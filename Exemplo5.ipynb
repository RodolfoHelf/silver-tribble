{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Machine Learning\n==\n\nO aprendizado de máquina é uma atividade relevante para o Cientista de Dados.\n\nPara saber mais sobre aprendizado de máquina, sua história e benefícios, leia os seguintes materiais:\n- https://en.wikipedia.org/wiki/Arthur_Samuel\n- https://www.wired.com/insights/2014/03/use-data-tell-future-understanding-machine-learning/\n\nSeguem alguns exemplos de aplicações de aprendizado de máquina:\n- filtragem de spam em emails (http://en.wikipedia.org/wiki/Email_filtering) \n- Reconhecimento Ótico de Caracteres (OCR)(http://en.wikipedia.org/wiki/Optical_character_recognition)\n- Sistemas de Recomendação (http://en.wikipedia.org/wiki/Recommender_systems)\n- Visão Computacional (http://en.wikipedia.org/wiki/Computer_vision)\n\nO aprendizado de máquina pode ser supervisionado ou não supervisionado. "
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Aprendizado Supervisionado\n--\n\nQuando temos alguns dados e sabemos a sua categoria, classe ou resultado esperado, podemos ensinar a máquina a predizer o resultado com nas características desses dados de treinamento. Para tanto, apresentamos os dados e o resultado esperado, e o modelo 'aprende' a dar a resposta esperada para os mesmos dados e para dados similares.\n\nMaiores detalhes em: http://en.wikipedia.org/wiki/Supervised_Learning\n\nAlgumas tarefas comuns de aprendizado supervisionado são:\n\n- Classificação (http://en.wikipedia.org/wiki/Statistical_classification)\n- Regressão (http://en.wikipedia.org/wiki/Regression_analysis\n\nMais abaixo, vamos trabalhar com Classificação.\n\nAprendizado não-supervisionado\n--\n\nO aprendizado não-supervisionado é usado quando não conhecemos muito bem o domínio da aplicação e queremos treinar um modelo sem ter um exemplo das respostas esperadas. Maiores detalhes em: http://en.wikipedia.org/wiki/Unsupervised_learning\n\nAlgumas tarefas comuns de aprendizado supervisionado são:\n\n- Análise de conglomerados (Cluster Analysis)(http://en.wikipedia.org/wiki/Data_clustering)\n- PCA - Correlaciona ou avalia se variáveis são correlacionadas (http://www.wikipedia.org/wiki/principal_component_analysis)\n\nEm outra aula vamos estudar um pouco mais sobre Análise de Conglomerados."
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Classificação \n--\n\nPara aprender como podemos criar um classificador, vamos utilicar a biblioteca 'sklearn', que possui diversos classificadores pré-programados. \n\nPara gerar um classificador e iniciar a classificação de elementos, necessitamos seguir um conjunto de passos:\n\n1. Definir um conjunto de dados de treinamento e um conjunto de testes. Para nossa sorte, a biblioteca 'sklearn' já vem com vários conjuntos de dados que podemos usar como exemplos. Eles já estão preparados, anotados e subdivididos nesses 2 conjuntos.\n\n2. Carregar e representar os elementos em memória. Vamos utilizar um conjunto de arrays, um para cada conjunto (treino e teste), além de um array contendo a informação de qual é o resultado (classe) esperada para cada elemento. \n\n3. Treinar modelo. De posse das representações de cada elemento (dados + classe esperada), podemos iniciar a etapa de treinamento do classificador. Existem vários classificadores. Vamos escolher um dos mais simples. A ideia consiste em mostrar ao modelo um elemento e sua classe esperada e esperar que o modelo aprenda. \n\n4. Realizar a predição de categorias. Ou seja, apresentar um elemento ao modelo treinado e receber sua categoria prevista pelo modelo.\n\n5. Avaliar o modelo, i.e., verificar se as categorias preditas pelo modelo são iguais as previstas (originais) e calcular o grau de acurácia. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# seleciona o módulo de data-sets da biblioteca 'sklearn' e permite carregar um deles\n# perceba que a biblioteca já possui vários data-sets pré-processados e catalogados para utilização imediata\nfrom sklearn import datasets\n\n# carrega o data-set 'Iris' (detalhes em: https://en.wikipedia.org/wiki/Iris_flower_data_set)\niris = datasets.load_iris()\n\n# mostra o conjunto de dados lido\niris.data",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Perceba que o conjunto de dados é composto de vários elementos (um por linha), cada um com 4 atributos!\n\nO trecho seguinte comprova isso, demonstrando o shape (formato) dos dados (i.e., 150 elementos de 4 dimensões):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# mostra o formato dos dados (quantidade de elementos, dimensões\niris.data.shape",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "(150, 4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "O conjunto de dados foi pré-analisado e cada elemento foi categorizado por um especialista. Ao todo, existem 3 classes, representadas pelos códigos 0, 1 e 2. Veja o conjunto de dados e seu formato:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# classes esperadas\niris.target",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# mostra o formato dos dados (150 elementos indicando as classes de cada)\niris.target.shape",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "(150,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Vamos agora iniciar o processo de treinamento e avaliar o quão correto ele é. Uma abordagem clássica consiste em dividir o conjunto de dados em duas partes: uma para o treinamento do modelo e a outra para testes do modelo. Uma independente da outra.\n\nPara tanto, vamos dividir o conjunto de dados em duas partes, utilizando o comando 'train_test_split':"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import model_selection\n\n# divisão em dados de treino e dados de teste com a função 'train_test_split'\n# ela recebe 3 parâmetros: os dados, as categorias e a proporção de dados que será separada para testes (40%, no caso) \nX_treinamento, X_teste, y_treinamento, y_teste = model_selection.train_test_split(iris.data, iris.target, test_size=0.7)\n\n# X_treinamento armazenará o subconjunto de dados escolhido para o treinamento do modelo (60% dos dados)\n# X_teste armazenará o subconjunto de dados escolhido para teste do modelo (40% dos dados)\n# x_treinamento armazena as classes de cada elemento do conjunto de treinamento\n# y_teste armazena as classes de cada elemento do conjunto de testes\n\n# Veja seu conteudo:",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_treinamento",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "array([[6.3, 3.3, 4.7, 1.6],\n       [5.8, 2.7, 3.9, 1.2],\n       [5.7, 2.6, 3.5, 1. ],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.6, 3. , 4.4, 1.4],\n       [5.8, 4. , 1.2, 0.2],\n       [6.7, 3. , 5. , 1.7],\n       [5.1, 3.5, 1.4, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [4.6, 3.4, 1.4, 0.3],\n       [5.4, 3.7, 1.5, 0.2],\n       [5.9, 3. , 4.2, 1.5],\n       [5.4, 3. , 4.5, 1.5],\n       [6.2, 3.4, 5.4, 2.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [5. , 3.4, 1.6, 0.4],\n       [5.1, 3.8, 1.9, 0.4],\n       [6. , 2.2, 4. , 1. ],\n       [7.6, 3. , 6.6, 2.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.6, 2.5, 3.9, 1.1],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.7, 4.4, 1.5, 0.4],\n       [4.6, 3.2, 1.4, 0.2],\n       [7.2, 3.6, 6.1, 2.5],\n       [4.7, 3.2, 1.6, 0.2],\n       [5.8, 2.6, 4. , 1.2],\n       [6.8, 3. , 5.5, 2.1],\n       [5.3, 3.7, 1.5, 0.2],\n       [6.4, 3.1, 5.5, 1.8],\n       [5.8, 2.8, 5.1, 2.4],\n       [5.1, 2.5, 3. , 1.1],\n       [6. , 3. , 4.8, 1.8],\n       [7.2, 3.2, 6. , 1.8],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.3, 3.3, 6. , 2.5],\n       [4.5, 2.3, 1.3, 0.3],\n       [6.1, 2.8, 4. , 1.3],\n       [4.8, 3.4, 1.6, 0.2],\n       [7.7, 2.8, 6.7, 2. ],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.1, 3. , 4.6, 1.4],\n       [6. , 2.7, 5.1, 1.6],\n       [5.1, 3.7, 1.5, 0.4],\n       [5.8, 2.7, 4.1, 1. ],\n       [7.1, 3. , 5.9, 2.1],\n       [6.4, 2.9, 4.3, 1.3],\n       [5.1, 3.3, 1.7, 0.5],\n       [5. , 3.6, 1.4, 0.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [4.4, 2.9, 1.4, 0.2],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.5, 3. , 5.5, 1.8],\n       [7. , 3.2, 4.7, 1.4],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.2, 3.5, 1.5, 0.2],\n       [7.9, 3.8, 6.4, 2. ],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.7, 3.3, 5.7, 2.1],\n       [5.5, 2.3, 4. , 1.3],\n       [5.5, 3.5, 1.3, 0.2],\n       [6.2, 2.8, 4.8, 1.8],\n       [5.6, 3. , 4.1, 1.3],\n       [5.4, 3.9, 1.7, 0.4],\n       [6.1, 2.6, 5.6, 1.4],\n       [6.1, 3. , 4.9, 1.8],\n       [5.5, 2.4, 3.8, 1.1],\n       [5. , 3.3, 1.4, 0.2],\n       [6.4, 2.8, 5.6, 2.1],\n       [4.9, 3.1, 1.5, 0.1],\n       [5. , 2. , 3.5, 1. ],\n       [5.7, 3. , 4.2, 1.2],\n       [4.9, 3. , 1.4, 0.2],\n       [5.2, 2.7, 3.9, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.7, 2.5, 5.8, 1.8],\n       [5.9, 3.2, 4.8, 1.8],\n       [4.6, 3.6, 1. , 0.2],\n       [4.8, 3.4, 1.9, 0.2],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.4, 2.7, 5.3, 1.9],\n       [4.8, 3. , 1.4, 0.3],\n       [5.6, 3. , 4.5, 1.5],\n       [4.4, 3. , 1.3, 0.2],\n       [6.9, 3.2, 5.7, 2.3]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_teste",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "array([[7.4, 2.8, 6.1, 1.9],\n       [4.8, 3.1, 1.6, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [7.2, 3. , 5.8, 1.6],\n       [6.4, 3.2, 5.3, 2.3],\n       [5.1, 3.5, 1.4, 0.3],\n       [6.7, 3.1, 4.7, 1.5],\n       [4.7, 3.2, 1.3, 0.2],\n       [6.8, 3.2, 5.9, 2.3],\n       [5.1, 3.4, 1.5, 0.2],\n       [6.7, 3.1, 4.4, 1.4],\n       [4.9, 2.5, 4.5, 1.7],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.8, 2.8, 4.8, 1.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [6.6, 2.9, 4.6, 1.3],\n       [4.8, 3. , 1.4, 0.1],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 2.7, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [6. , 2.9, 4.5, 1.5],\n       [6.5, 3. , 5.8, 2.2],\n       [5.7, 3.8, 1.7, 0.3],\n       [6.9, 3.1, 5.1, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.6, 2.9, 3.6, 1.3],\n       [4.9, 3.1, 1.5, 0.1],\n       [7.7, 3.8, 6.7, 2.2],\n       [5. , 3.5, 1.6, 0.6],\n       [7.7, 2.6, 6.9, 2.3],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.7, 2.8, 4.1, 1.3],\n       [5. , 2.3, 3.3, 1. ],\n       [6.4, 3.2, 4.5, 1.5],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.5, 0.2],\n       [5.9, 3. , 5.1, 1.8],\n       [4.9, 3.1, 1.5, 0.1],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.3, 2.7, 4.9, 1.8],\n       [5.7, 2.5, 5. , 2. ],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [5.2, 3.4, 1.4, 0.2],\n       [6. , 2.2, 5. , 1.5],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.9, 3.1, 5.4, 2.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [6. , 3.4, 4.5, 1.6],\n       [4.4, 3.2, 1.3, 0.2],\n       [5.1, 3.8, 1.6, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [5.5, 2.5, 4. , 1.3],\n       [6.5, 3. , 5.2, 2. ]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Veja seus formatos e perceba que as quantidades estão corretas:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_treinamento.shape, y_treinamento.shape",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "((60, 4), (60,))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_teste.shape, y_teste.shape",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "((90, 4), (90,))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "O próximo passo consiste em treinar um classificador. Existem vários classificadores implementados. \n\nUm dos classificadores mais simples é o dos 'K Vizinhos mais próximos' (KNN). Para informações sobre o seu funcionamento, leia: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm.\n\nA biblioteca 'sklearn' implementa-o através do módulo 'KNeighborsClassifier'. \n\nVeja o exemplo:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_treinamento, y_treinamento) \n\nKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finalmente, vamos avaliar o quão bem o classificador funciona. Para tanto, basta chamar a função 'score' do modelo e passar o conjunto de dados de teste e os resultados esperados para cada elemento. A linha seguinte faz isso. O resultado é um número entre 0.0 e 1.0 indicando a acurácia do modelo. Quanto mais próximo de 1.0, melhor. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "knn.score(X_teste, y_teste)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "0.9666666666666667"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Podemos utilizar o modelo para avaliar (predizer) qual seria a classe de um elemento qualquer ou de um conjunto de elementos:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": " knn.predict([[ 6.4,  2.9,  4.3,  1.3]])",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "array([1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": " knn.predict(X_teste)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "array([2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 2, 2, 1, 0, 1, 0, 2, 1,\n       1, 1, 1, 2, 0, 2, 2, 0, 1, 0, 2, 0, 2, 1, 1, 1, 1, 0, 0, 2, 0, 2,\n       2, 2, 2, 2, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 1, 2])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Como exemplo adicional, vamos usar uma Support Vector Machine (SVM) com núcleo linear (para informações sobre o funcionamento de uma SVM, leia: https://en.wikipedia.org/wiki/Support_vector_machine."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import svm\n\n# cria um classificador SVM e o armazena em clf:\nclf = svm.SVC(kernel='linear', C=1).fit(X_treinamento, y_treinamento)\n\n# mostra informações sobre o classificador gerado:\nclf",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Vamos novamente avaliar o resultado do treinamento do classificador (e comparar com o anterior). Usaremos novamente função 'score', passando o conjunto de dados de teste e os resultados esperados para cada elemento:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clf.score(X_teste, y_teste)",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "0.9666666666666667"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(clf.predict([[ 6.4,  2.9,  4.3,  1.3]]))",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[1]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Exercício\n--\n\nRefaça os experimentos, mas utilizando outros classificadores. \n\nAlgumas possibilidades são (entre outros):\n\n- Naive Bayes (GaussianNB)\n- Regressão Logística (LogisticRegression)\n- Rede Neural (MLPClassifier)\n- Random Forest (RandomForestClassifier)\n- Gradient Boosting (GradientBoostingClassifier)\n- Árvore de Decisão (DecisionTreeClassifier)\n\nColoque os resultados em uma tabela (dataframe) e depois mostre na tela o resultado do treinamento dos modelos, por classificador. \n\nUma comparação (com exemplo de uso) pode ser encontrada em: http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n\nA documentação dos classificadores (aprendizado supervisionado) pode ser obtida em: http://scikit-learn.org/stable/supervised_learning.html\n\nUm pequeno tutorial de uso pode ser visto em: http://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nindex = [\"GaussianNB\",\"DecisionTree\",\"LogisticRegression\"]\ncolumns = [\"Score\"]\ndata = []\n\nfrom sklearn.naive_bayes import GaussianNB\nclf = GaussianNB().fit(X_treinamento, y_treinamento)\ndata.append(clf.score(X_teste, y_teste))\n\nimport sklearn\nclf = sklearn.tree.DecisionTreeClassifier().fit(X_treinamento, y_treinamento)\ndata.append(clf.score(X_teste, y_teste))\n\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression().fit(X_treinamento, y_treinamento)\ndata.append(clf.score(X_teste, y_teste))\n\ndf = pd.DataFrame(data,columns = columns,index = index)\ndf",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.933333</td>\n    </tr>\n    <tr>\n      <th>DecisionTree</th>\n      <td>0.933333</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.952381</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                       Score\nGaussianNB          0.933333\nDecisionTree        0.933333\nLogisticRegression  0.952381"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Desafio\n--\nEscolha outra coleção do sklearn (veja outras opções de datasets em: http://scikit-learn.org/stable/datasets/index.html#datasets) ou do seguinte repositório e realize sua classificação!\n\n- http://archive.ics.uci.edu/ml/datasets.html\n\nOu ainda, pegue dados do Moodle ou de outro conjunto qualquer para testar seus conhecimentos. Não se esqueça de que é necessário ter os elementos e os resultados esperados!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}